{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import nltk\n",
    "from nltk.corpus import movie_reviews\n",
    "\n",
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "             for category in movie_reviews.categories()\n",
    "             for fileid in movie_reviews.fileids(category)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Documents: 2000\n",
      "First Review: (['apparently', ',', 'when', 'crap', 'calls', ',', 'jim', 'carrey', 'answers', '.', 'here', 'he', 'is', ',', 'mugging', 'it', 'up', 'in', 'countless', 'unfunny', 'ways', 'for', 'the', 'fifth', 'time', ',', 'his', 'second', 'go', '-', 'around', 'in', 'the', 'role', 'of', 'pet', 'detective', 'ace', 'ventura', '.', 'that', 'means', 'more', 'talking', 'ass', '-', 'cracks', ',', 'penis', 'jokes', 'and', 'cries', 'of', '\"', 'al', '-', 'l', '-', 'l', '-', 'l', '-', 'l', '-', 'l', '-', 'l', '-', 'l', '-', 'l', '-', 'l', '-', 'lrighty', 'then', '.', '\"', 'it', 'all', 'adds', 'up', 'to', 'a', 'sequel', 'that', 'makes', 'the', 'original', 'resemble', 'schindler', \"'\", 's', 'list', 'in', 'terms', 'of', 'dramatic', 'merit', ',', 'or', 'lack', 'of', '.', 'granted', ',', 'there', 'are', 'a', 'few', 'laughs', 'amid', 'the', 'constant', 'barrage', 'of', 'pre', '-', 'school', 'humor', ',', 'but', 'anyone', 'who', 'appreciates', 'good', 'comedy', 'will', 'bang', 'their', 'head', 'against', 'the', 'wall', 'ten', 'times', 'for', 'every', 'minor', 'chuckle', '.', 'it', \"'\", 's', 'a', 'painful', 'experience', 'for', 'anyone', 'with', 'a', 'brain', '.', 'ace', 'is', 'distraught', 'after', 'accidentally', 'dropping', 'a', 'racoon', 'into', 'a', 'canyon', '(', 'in', 'a', 'parody', 'of', 'the', 'opening', 'scene', 'of', 'sylvester', 'stallone', \"'\", 's', 'cliffhanger', ',', 'jim', 'carrey', 'being', 'the', 'only', 'person', 'who', 'can', 'make', 'stallone', 'look', 'like', 'a', 'college', 'professor', 'in', 'terms', 'of', 'intellect', ',', 'or', 'lack', 'of', ')', 'and', 'decides', 'to', 'retire', 'to', 'the', 'mountains', 'of', 'tibet', 'to', 'gain', 'a', 'higher', 'level', 'of', 'consciousness', '(', 'or', ',', 'in', 'his', 'case', ',', 'a', 'level', 'of', 'consciousness', ')', '.', 'but', 'he', 'is', 'pulled', 'out', 'of', 'retirement', 'to', 'the', 'tune', 'of', '$', '20', ',', '000', 'to', 'retrieve', 'a', 'sacred', 'white', 'bat', 'for', 'an', 'african', 'tribe', '.', 'why', 'africa', '?', 'so', 'carrey', 'can', 'disguise', 'himself', 'nude', 'inside', 'a', 'fake', 'rhino', 'and', 'later', 'climb', 'out', 'the', 'rear', 'end', 'as', 'a', 'tourist', 'family', 'watches', '(', '\"', 'look', ',', 'the', 'rhino', \"'\", 's', 'about', 'to', 'give', 'birth', '!', '\"', ')', '.', 'if', 'that', 'seems', 'like', 'hee', '-', 'haw', 'humor', 'to', 'you', ',', 'by', 'all', 'means', ',', 'see', 'the', 'movie', '.', 'if', 'not', ',', 'claim', 'your', 'place', 'in', 'human', 'civilization', 'with', 'the', 'rest', 'of', 'us', '.', 'obviously', ',', 'there', 'are', 'quite', 'a', 'few', 'nonmembers', 'of', 'civilization', 'who', 'made', 'this', 'movie', ',', 'like', 'the', 'first', 'ace', 'ventura', 'film', '(', 'i', 'use', 'the', 'word', '\"', 'film', '\"', 'only', 'because', 'it', 'was', 'filmed', ',', 'not', 'because', 'there', \"'\", 's', 'any', 'level', 'of', 'artistic', 'merit', '.', ')', ',', 'a', 'huge', 'success', '.', 'in', 'fact', ',', 'carrey', 'only', 'has', 'a', 'career', 'because', 'of', 'the', 'decline', 'of', 'intelligence', 'in', 'our', 'culture', '.', 'you', 'may', 'say', 'to', 'me', ',', '\"', 'but', 'andrew', ',', 'look', 'at', 'jerry', 'lewis', '.', 'he', 'was', 'born', 'with', 'a', 'negative', 'i', '.', 'q', '.', 'and', 'look', 'how', 'popular', 'he', 'was', 'thirty', 'years', 'ago', '.', '\"', 'maybe', ',', 'but', 'i', 'still', 'say', 'jerry', 'lewis', 'is', 'a', 'notch', 'or', 'two', 'up', 'on', 'the', 'comedic', 'ladder', 'because', 'he', 'never', 'actually', 'did', 'an', 'impression', 'in', 'a', 'movie', 'of', 'a', 'rabid', 'bulldog', 'biting', 'off', 'a', 'man', \"'\", 's', 'testicles', '.', '.', '.', 'lewis', 'at', 'least', 'had', 'the', 'dignity', 'to', 'save', 'that', 'performance', 'for', 'when', 'company', 'came', 'over', '.'], 'neg')\n",
      "Most common words: [(',', 77717), ('the', 76529), ('.', 65876), ('a', 38106), ('and', 35576), ('of', 34123), ('to', 31937), (\"'\", 30585), ('is', 25195), ('in', 21822), ('s', 18513), ('\"', 17612), ('it', 16107), ('that', 15924), ('-', 15595)]\n",
      "The word happy: 215\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(documents)\n",
    "\n",
    "print('Number of Documents: {}'.format(len(documents)))\n",
    "print('First Review: {}'.format(documents[1]))\n",
    "\n",
    "all_words = []\n",
    "for w in movie_reviews.words():\n",
    "    all_words.append(w.lower())\n",
    "\n",
    "all_words = nltk.FreqDist(all_words)\n",
    "\n",
    "print('Most common words: {}'.format(all_words.most_common(15)))\n",
    "print('The word happy: {}'.format(all_words[\"happy\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39768\n"
     ]
    }
   ],
   "source": [
    "print(len(all_words))\n",
    "word_features = list(all_words.keys())[:4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_features(document):\n",
    "    words = set(document)\n",
    "    features = {}\n",
    "    for w in word_features:\n",
    "        features[w] = (w in words)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plot\n",
      ":\n",
      "two\n",
      "teen\n",
      "couples\n",
      "go\n",
      "to\n",
      "a\n",
      "church\n",
      "party\n",
      ",\n",
      "drink\n",
      "and\n",
      "then\n",
      "drive\n",
      ".\n",
      "they\n",
      "get\n",
      "into\n",
      "an\n",
      "accident\n",
      "one\n",
      "of\n",
      "the\n",
      "guys\n",
      "dies\n",
      "but\n",
      "his\n",
      "girlfriend\n",
      "continues\n",
      "see\n",
      "him\n",
      "in\n",
      "her\n",
      "life\n",
      "has\n",
      "nightmares\n",
      "what\n",
      "'\n",
      "s\n",
      "deal\n",
      "?\n",
      "watch\n",
      "movie\n",
      "\"\n",
      "sorta\n",
      "find\n",
      "out\n",
      "critique\n",
      "mind\n",
      "-\n",
      "fuck\n",
      "for\n",
      "generation\n",
      "that\n",
      "touches\n",
      "on\n",
      "very\n",
      "cool\n",
      "idea\n",
      "presents\n",
      "it\n",
      "bad\n",
      "package\n",
      "which\n",
      "is\n",
      "makes\n",
      "this\n",
      "review\n",
      "even\n",
      "harder\n",
      "write\n",
      "since\n",
      "i\n",
      "generally\n",
      "applaud\n",
      "films\n",
      "attempt\n",
      "break\n",
      "mold\n",
      "mess\n",
      "with\n",
      "your\n",
      "head\n",
      "such\n",
      "(\n",
      "lost\n",
      "highway\n",
      "&\n",
      "memento\n",
      ")\n",
      "there\n",
      "are\n",
      "good\n",
      "ways\n",
      "making\n",
      "all\n",
      "types\n",
      "these\n",
      "folks\n",
      "just\n",
      "didn\n",
      "t\n",
      "snag\n",
      "correctly\n",
      "seem\n",
      "have\n",
      "taken\n",
      "pretty\n",
      "neat\n",
      "concept\n",
      "executed\n",
      "terribly\n",
      "so\n",
      "problems\n",
      "well\n",
      "its\n",
      "main\n",
      "problem\n",
      "simply\n",
      "too\n",
      "jumbled\n",
      "starts\n",
      "off\n",
      "normal\n",
      "downshifts\n",
      "fantasy\n",
      "world\n",
      "you\n",
      "as\n",
      "audience\n",
      "member\n",
      "no\n",
      "going\n",
      "dreams\n",
      "characters\n",
      "coming\n",
      "back\n",
      "from\n",
      "dead\n",
      "others\n",
      "who\n",
      "look\n",
      "like\n",
      "strange\n",
      "apparitions\n",
      "disappearances\n",
      "looooot\n",
      "chase\n",
      "scenes\n",
      "tons\n",
      "weird\n",
      "things\n",
      "happen\n",
      "most\n",
      "not\n",
      "explained\n",
      "now\n",
      "personally\n",
      "don\n",
      "trying\n",
      "unravel\n",
      "film\n",
      "every\n",
      "when\n",
      "does\n",
      "give\n",
      "me\n",
      "same\n",
      "clue\n",
      "over\n",
      "again\n",
      "kind\n",
      "fed\n",
      "up\n",
      "after\n",
      "while\n",
      "biggest\n",
      "obviously\n",
      "got\n",
      "big\n",
      "secret\n",
      "hide\n",
      "seems\n",
      "want\n",
      "completely\n",
      "until\n",
      "final\n",
      "five\n",
      "minutes\n",
      "do\n",
      "make\n",
      "entertaining\n",
      "thrilling\n",
      "or\n",
      "engaging\n",
      "meantime\n",
      "really\n",
      "sad\n",
      "part\n",
      "arrow\n",
      "both\n",
      "dig\n",
      "flicks\n",
      "we\n",
      "actually\n",
      "figured\n",
      "by\n",
      "half\n",
      "way\n",
      "point\n",
      "strangeness\n",
      "did\n",
      "start\n",
      "little\n",
      "bit\n",
      "sense\n",
      "still\n",
      "more\n",
      "guess\n",
      "bottom\n",
      "line\n",
      "movies\n",
      "should\n",
      "always\n",
      "sure\n",
      "before\n",
      "given\n",
      "password\n",
      "enter\n",
      "understanding\n",
      "mean\n",
      "showing\n",
      "melissa\n",
      "sagemiller\n",
      "running\n",
      "away\n",
      "visions\n",
      "about\n",
      "20\n",
      "throughout\n",
      "plain\n",
      "lazy\n",
      "!\n",
      "okay\n",
      "people\n",
      "chasing\n",
      "know\n",
      "need\n",
      "how\n",
      "giving\n",
      "us\n",
      "different\n",
      "offering\n",
      "further\n",
      "insight\n",
      "down\n",
      "apparently\n",
      "studio\n",
      "took\n",
      "director\n",
      "chopped\n",
      "themselves\n",
      "shows\n",
      "might\n",
      "ve\n",
      "been\n",
      "decent\n",
      "here\n",
      "somewhere\n",
      "suits\n",
      "decided\n",
      "turning\n",
      "music\n",
      "video\n",
      "edge\n",
      "would\n",
      "actors\n",
      "although\n",
      "wes\n",
      "bentley\n",
      "seemed\n",
      "be\n",
      "playing\n",
      "exact\n",
      "character\n",
      "he\n",
      "american\n",
      "beauty\n",
      "only\n",
      "new\n",
      "neighborhood\n",
      "my\n",
      "kudos\n",
      "holds\n",
      "own\n",
      "entire\n",
      "feeling\n",
      "unraveling\n",
      "overall\n",
      "doesn\n",
      "stick\n",
      "because\n",
      "entertain\n",
      "confusing\n",
      "rarely\n",
      "excites\n",
      "feels\n",
      "redundant\n",
      "runtime\n",
      "despite\n",
      "ending\n",
      "explanation\n",
      "craziness\n",
      "came\n",
      "oh\n",
      "horror\n",
      "slasher\n",
      "flick\n",
      "packaged\n",
      "someone\n",
      "assuming\n",
      "genre\n",
      "hot\n",
      "kids\n",
      "also\n",
      "wrapped\n",
      "production\n",
      "years\n",
      "ago\n",
      "sitting\n",
      "shelves\n",
      "ever\n",
      "whatever\n",
      "skip\n",
      "where\n",
      "joblo\n",
      "nightmare\n",
      "elm\n",
      "street\n",
      "3\n",
      "7\n",
      "/\n",
      "10\n",
      "blair\n",
      "witch\n",
      "2\n",
      "crow\n",
      "9\n",
      "salvation\n",
      "4\n",
      "stir\n",
      "echoes\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "features = find_features(movie_reviews.words('neg/cv000_29416.txt'))\n",
    "for key, value in features.items():\n",
    "    if value == True:\n",
    "        print (key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500\n",
      "500\n",
      "SVC Accuracy: 80.60000000000001\n"
     ]
    }
   ],
   "source": [
    "featuresets = [(find_features(rev), category) for (rev, category) in documents]\n",
    "from sklearn import model_selection\n",
    "seed = 1\n",
    "training, testing = model_selection.train_test_split(featuresets, test_size = 0.25, random_state=seed)\n",
    "\n",
    "print(len(training))\n",
    "print(len(testing))\n",
    "\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.svm import SVC\n",
    "model = SklearnClassifier(SVC(kernel = 'linear'))\n",
    "model.train(training)\n",
    "accuracy = nltk.classify.accuracy(model, testing)*100\n",
    "print(\"SVC Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
